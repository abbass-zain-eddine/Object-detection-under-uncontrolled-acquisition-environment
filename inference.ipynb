{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/meituan/YOLOv6/blob/main/inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q-0tGltfFeQh",
    "outputId": "94af1d35-e4a0-4c09-e5e9-ae89064823c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'YOLOv6'...\n",
      "remote: Enumerating objects: 522, done.\u001b[K\n",
      "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
      "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
      "remote: Total 522 (delta 1), reused 7 (delta 1), pack-reused 507\u001b[K\n",
      "Receiving objects: 100% (522/522), 1.34 MiB | 15.44 MiB/s, done.\n",
      "Resolving deltas: 100% (227/227), done.\n",
      "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Clone and install MT-YOLOv6\n",
    "!cd YOLOv6\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(weights='/home/zeineddine/ICIPCompet/zeineddine-142224/runs/train/exp19/weights/best_ckpt.pt', source='/home/zeineddine/ICIPCompet/zeineddine-142224/datanew/dataset/images/test', webcam=False, webcam_addr='0', yaml='datanew/dataset.yaml', img_size=[640, 640], conf_thres=0.4, iou_thres=0.45, max_det=1000, device='0', save_txt=True, not_save_img=False, save_dir=None, view_img=False, classes=None, agnostic_nms=False, project='runs/inference', name='exp', hide_labels=False, hide_conf=False, half=False)\n",
      "Save directory already existed\n",
      "Loading checkpoint from /home/zeineddine/ICIPCompet/zeineddine-142224/runs/train/exp19/weights/best_ckpt.pt\n",
      "\n",
      "Fusing model...\n",
      "Switch model to deploy modality.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zeineddine/ICIPCompet/zeineddine-142224/tools/infer.py\", line 120, in <module>\n",
      "    main(args)\n",
      "  File \"/home/zeineddine/ICIPCompet/zeineddine-142224/tools/infer.py\", line 115, in main\n",
      "    run(**vars(args))\n",
      "  File \"/home/zeineddine/.local/lib/python3.10/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/zeineddine/ICIPCompet/zeineddine-142224/tools/infer.py\", line 107, in run\n",
      "    inferer = Inferer(source, webcam, webcam_addr, weights, device, yaml, img_size, half)\n",
      "  File \"/home/zeineddine/ICIPCompet/zeineddine-142224/yolov6/core/inferer.py\", line 50, in __init__\n",
      "    self.model(torch.zeros(1, 3, *self.img_size).to(self.device).type_as(next(self.model.model.parameters())))  # warmup\n",
      "  File \"/home/zeineddine/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/zeineddine/ICIPCompet/zeineddine-142224/yolov6/layers/common.py\", line 486, in forward\n",
      "    y, _ = self.model(im)\n",
      "  File \"/home/zeineddine/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/zeineddine/ICIPCompet/zeineddine-142224/yolov6/models/yolo.py\", line 34, in forward\n",
      "    x = self.backbone(x)\n",
      "  File \"/home/zeineddine/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/zeineddine/ICIPCompet/zeineddine-142224/yolov6/models/efficientrep.py\", line 485, in forward\n",
      "    x = self.stem(x)\n",
      "  File \"/home/zeineddine/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/zeineddine/ICIPCompet/zeineddine-142224/yolov6/layers/common.py\", line 75, in forward\n",
      "    return self.block(x)\n",
      "  File \"/home/zeineddine/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/zeineddine/ICIPCompet/zeineddine-142224/yolov6/layers/common.py\", line 42, in forward_fuse\n",
      "    return self.act(self.conv(x))\n",
      "  File \"/home/zeineddine/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/zeineddine/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 463, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/home/zeineddine/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "RuntimeError: Given groups=1, weight of size [64, 4, 3, 3], expected input[1, 3, 640, 640] to have 4 channels, but got 3 channels instead\n"
     ]
    }
   ],
   "source": [
    "!python tools/infer.py --weights runs/train/exp/weights/best_ckpt.pt --source /datanew/dataset/images/test --save-txt"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Copy of Untitled2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
